"""Tools for model selection, such as cross validation and hyper-parameter tuning."""

# Authors: The scikit-learn developers
# SPDX-License-Identifier: BSD-3-Clause

import typing

from ._classification_threshold import (
    FixedThresholdClassifier,
    TunedThresholdClassifierCV,
)
from ._plot import LearningCurveDisplay, ValidationCurveDisplay
from ._search import GridSearchCV, ParameterGrid, ParameterSampler, RandomizedSearchCV
from ._split import (
    BaseCrossValidator,
    BaseShuffleSplit,
    GroupKFold,
    GroupShuffleSplit,
    KFold,
    LeaveOneGroupOut,
    LeaveOneOut,
    LeavePGroupsOut,
    LeavePOut,
    PredefinedSplit,
    RepeatedKFold,
    RepeatedStratifiedKFold,
    ShuffleSplit,
    StratifiedGroupKFold,
    StratifiedKFold,
    StratifiedShuffleSplit,
    TimeSeriesSplit,
    check_cv,
    train_test_split,
)
from ._validation import (
    cross_val_predict,
    cross_val_score,
    cross_validate,
    learning_curve,
    permutation_test_score,
    validation_curve,
)

if typing.TYPE_CHECKING:
    # Avoid errors in type checkers (e.g. mypy) for experimental estimators.
    # TODO: remove this check once the estimator is no longer experimental.
<<<<<<< HEAD
    from ._search_successive_halving import (  # noqa: F401
=======
    from ._search_successive_halving import (  # noqa
>>>>>>> 9c5f2989031ba54019bec835b7ecb3f5768f2dcf
        HalvingGridSearchCV,
        HalvingRandomSearchCV,
    )


__all__ = [
    "BaseCrossValidator",
    "BaseShuffleSplit",
<<<<<<< HEAD
    "FixedThresholdClassifier",
    "GridSearchCV",
    "GroupKFold",
    "GroupShuffleSplit",
    "KFold",
    "LearningCurveDisplay",
=======
    "GridSearchCV",
    "TimeSeriesSplit",
    "KFold",
    "GroupKFold",
    "GroupShuffleSplit",
>>>>>>> 9c5f2989031ba54019bec835b7ecb3f5768f2dcf
    "LeaveOneGroupOut",
    "LeaveOneOut",
    "LeavePGroupsOut",
    "LeavePOut",
<<<<<<< HEAD
=======
    "RepeatedKFold",
    "RepeatedStratifiedKFold",
>>>>>>> 9c5f2989031ba54019bec835b7ecb3f5768f2dcf
    "ParameterGrid",
    "ParameterSampler",
    "PredefinedSplit",
    "RandomizedSearchCV",
<<<<<<< HEAD
    "RepeatedKFold",
    "RepeatedStratifiedKFold",
    "ShuffleSplit",
    "StratifiedGroupKFold",
    "StratifiedKFold",
    "StratifiedShuffleSplit",
    "TimeSeriesSplit",
    "TunedThresholdClassifierCV",
    "ValidationCurveDisplay",
=======
    "ShuffleSplit",
    "StratifiedKFold",
    "StratifiedGroupKFold",
    "StratifiedShuffleSplit",
    "FixedThresholdClassifier",
    "TunedThresholdClassifierCV",
>>>>>>> 9c5f2989031ba54019bec835b7ecb3f5768f2dcf
    "check_cv",
    "cross_val_predict",
    "cross_val_score",
    "cross_validate",
    "learning_curve",
<<<<<<< HEAD
    "permutation_test_score",
    "train_test_split",
    "validation_curve",
=======
    "LearningCurveDisplay",
    "permutation_test_score",
    "train_test_split",
    "validation_curve",
    "ValidationCurveDisplay",
>>>>>>> 9c5f2989031ba54019bec835b7ecb3f5768f2dcf
]


# TODO: remove this check once the estimator is no longer experimental.
def __getattr__(name):
    if name in {"HalvingGridSearchCV", "HalvingRandomSearchCV"}:
        raise ImportError(
            f"{name} is experimental and the API might change without any "
            "deprecation cycle. To use it, you need to explicitly import "
            "enable_halving_search_cv:\n"
            "from sklearn.experimental import enable_halving_search_cv"
        )
    raise AttributeError(f"module {__name__} has no attribute {name}")
